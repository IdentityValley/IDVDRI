[
  {
    "Criterion/Metric Name": "Digital Literacy Policy & Governance",
    "DRG Short Code": "1",
    "Question": "To what extent does the organisation have a formal accessibility policy/strategy with an active governance body overseeing its implementation?",
    "Rationale": "Policy and governance turn intentions into accountable practice, ensuring digital literacy efforts are resourced, coordinated, and sustained.",
    "Scoring Logic": "0=None; 1=Initial; 2=Formal policy; 3=Policy with governance; 4=Active governance; 5=Embedded practice",
    "Legend": "None – no policy or governance; Ad hoc – informal practices/awareness; Formal policy – policy exists and communicated; Policy with governance – governance body meets occasionally; Active governance – governance with monitoring and updates; Embedded practice – regular review and visible influence on decisions;",
    "Primary DRG": "DRG#1: Digital Literacy",
    "Other Applicable DRGs": "–"
  },
  {
    "Criterion/Metric Name": "Capacity building",
    "DRG Short Code": "1",
    "Question": "To what extent does the organisation provide training and capacity building for staff on the responsible use of digital technologies (e.g., data use, privacy, accessibility, AI)?",
    "Rationale": "Equipping staff with practical skills embeds responsible practices in day‑to‑day work, reducing risks and improving user outcomes.",
    "Scoring Logic": "0=None; 1=Ad hoc; 2=Basic; 3=Structured; 4=Embedded",
    "Legend": "None – no training on responsible use of digital technologies; Ad hoc – occasional, one-off sessions without follow-up; Basic – training available for some staff, but limited in scope or depth; Structured – regular program for relevant staff, supporting practical application; Embedded – training part of ongoing staff development and business processes, regularly updated and improved",
    "Primary DRG": "DRG#1: Digital Literacy",
    "Other Applicable DRGs": ""
  },
  {
    "Criterion/Metric Name": "Multilingual & Clear Communication",
    "DRG Short Code": "1",
    "Question": "How broadly and reliably are key digital services and user communications offered in the main languages of your user base, with usable, quality translations?",
    "Rationale": "Multilingual services promote inclusion and equal access, reducing barriers for users who do not speak the default language.",
    "Scoring Logic": "0 = No multilingual support; 1 = Minimal coverage; 2 = Basic multilingual provision; 3 = Moderate coverage; 4 = High coverage; 5 = Best practice / fully inclusive",
    "Legend": "Minimal – few document/services, poorly translated; Basic – key user-facing services and policies available in 1-2 additional major languages; Moderate – core services consistently available in 2+ languages covering the majority of user base; High – Broad range of services and support available in several languages, translations are professionally maintained and updated; Best-practice – Comprehensive multilingual support across all digital content and customer support channels, tailored to user demographics, regularly reviewed",
    "Primary DRG": "DRG#1: Digital Literacy",
    "Other Applicable DRGs": "DRG#6: Transparency"
  },
  {
    "Criterion/Metric Name": "Security Certification/Compliance",
    "DRG Short Code": "2",
    "Question": "Which statement best describes the organisations adoption and ongoing maintenance of recognised security standards (e.g., ISO/IEC 27001, SOC 2)?",
    "Rationale": "Recognised standards and their maintenance signal robust security practices and strengthen trust with customers and regulators.",
    "Scoring Logic": "0=None; 1=Aligned; 2=In progress; 3=Certified; 4=Maintained; 5=Best practice",
    "Legend": "None – no recognized certification; Aligned – practices informally aligned with a standard but no certification; In progress – formal certification process underway; Certified – formally certified to one recognized standard (e.g., ISO/IEC 27001, SOC 2); Maintained – certification actively renewed, monitored, and internally audited; Best practice – certification maintained with regular external audits and demonstrated continuous improvement",
    "Primary DRG": "DRG#2: Cybersecurity",
    "Other Applicable DRGs": "DRG#5: Trustworthy Algorithms"
  },
  {
    "Criterion/Metric Name": "Security Awareness Training Coverage",
    "DRG Short Code": "2",
    "Question": "To what extent does the organisation run a regular cybersecurity awareness program with required refreshers for relevant staff?",
    "Rationale": "People are a primary attack vector; consistent awareness training reduces the likelihood and impact of security incidents.",
    "Scoring Logic": "0=None; 1=Ad hoc; 2=Basic; 3=Structured; 4=Mandatory; 5=Embedded",
    "Legend": "None – no cybersecurity awareness training offered; Ad hoc – occasional or optional training without consistency; Basic – limited training (e.g., onboarding only or selected roles); Structured – organisation-wide program exists but not enforced; Mandatory – regular, compulsory training with refreshers for all staff; Embedded – training is continuous, role-specific, regularly updated, and effectiveness is measure",
    "Primary DRG": "DRG#2: Cybersecurity",
    "Other Applicable DRGs": "DRG#1: Digital Literacy"
  },
  {
    "Criterion/Metric Name": "Incident response plan",
    "DRG Short Code": "2",
    "Question": "Does the organisation have a formal, documented incident response plan covering detection, response, and recovery?",
    "Rationale": "A documented plan enables fast, coordinated action during incidents, limiting damage and speeding recovery.",
    "Scoring Logic": "0 = No; 3= Yes",
    "Legend": "None – no formalised incident response plan or process; Exists – formal, documented incident response strategy and process established (covering detection, response, and recovery)",
    "Primary DRG": "DRG#2: Cybersecurity",
    "Other Applicable DRGs": ""
  },
  {
    "Criterion/Metric Name": "Data Subject Requests (Volume & Response Time)",
    "DRG Short Code": "3",
    "Question": "How consistent and timely is the organisations process for handling data subject requests (e.g., access, correction, deletion), and how clear is the user experience?",
    "Rationale": "Reliable handling of requests demonstrates respect for individual rights, improves user trust, and reduces operational and reputational risk.",
    "Scoring Logic": "0=None; 1=Ad hoc; 2=Manual; 3=Consistent; 4=Timely; 5=User-centric",
    "Legend": "None – no process to handle data subject requests; Ad hoc – requests handled inconsistently, delays common; Manual – process exists but slow, depends on individual staff capacity; Consistent – requests handled reliably with defined steps, usually resolved within a reasonable timeframe; Timely – requests resolved quickly and predictably, supported by tools or streamlined processes; User-centric – requests resolved promptly with clear communication and support, process designed to be transparent and user-friendly",
    "Primary DRG": "DRG#3: Privacy",
    "Other Applicable DRGs": "DRG#6: Transparency, DRG#7: Human Agency"
  },
  {
    "Criterion/Metric Name": "Privacy Governance & Accountability",
    "DRG Short Code": "3",
    "Question": "What level of privacy governance is in place (e.g., assigned responsibility, dedicated DPO, clear reporting and oversight)?",
    "Rationale": "Clear accountability ensures privacy risks are managed proactively and escalated appropriately across the organisation.",
    "Scoring Logic": "0=None; 1=Informal; 2=Assigned; 3=Dedicated; 4=Structured; 5=Integrated",
    "Legend": "None – no privacy governance; Informal – handled ad hoc by IT/legal without mandate; Assigned – responsibility added to existing role (e.g., compliance officer); Dedicated – appointed DPO or privacy lead, limited influence; Structured – DPO with clear mandate, reporting line, regular oversight; Integrated – privacy embedded across departments with executive/board visibility",
    "Primary DRG": "DRG#3: Privacy",
    "Other Applicable DRGs": "DRG#6: Transparency"
  },
  {
    "Criterion/Metric Name": "PET adoption",
    "DRG Short Code": "3",
    "Question": "To what extent does the organisation adopt privacy‑enhancing technologies (beyond baseline compliance) in systems handling sensitive data?",
    "Rationale": "Going beyond minimum compliance with PETs reduces data exposure and enables privacy‑preserving innovation.",
    "Scoring Logic": "0=None; 1=Emerging; 2=Established; 3=Leading",
    "Legend": "None – only baseline compliance (e.g., anonymisation, encryption); Emerging – pilots of PETs in limited projects (e.g., secure enclaves, small-scale differential privacy); Established – PETs systematically applied in core processes (e.g., tokenization, differential privacy in production, privacy-preserving ML); Leading – PETs as differentiator with cutting-edge use (e.g., homomorphic encryption, zero-knowledge proofs, multi-party computation across business lines)",
    "Primary DRG": "DRG#3: Privacy",
    "Other Applicable DRGs": "DRG#2: Cybersecurity"
  },
  {
    "Criterion/Metric Name": "User Consent and Preference Management",
    "DRG Short Code": "4",
    "Question": "How effectively can users view and manage consent and data preferences through usable tools and dashboards?",
    "Rationale": "Meaningful user control supports fairness and autonomy and lowers complaints by making choices clear and actionable.",
    "Scoring Logic": "0=None; 1=Basic; 2=Standard; 3=Enhanced; 4=Comprehensive; 5=User-centric",
    "Legend": "None – no user control mechanisms; Basic – limited options (e.g., cookie banner with accept only); Standard – consent dashboards or preference managers with basic choices; Enhanced – users can access, correct, or delete data via clear processes; Comprehensive – self-service tools covering multiple rights (consent, data access, deletion, portability); User-centric – intuitive, transparent tools with real-time control and clear explanations",
    "Primary DRG": "DRG#4: Data Fairness",
    "Other Applicable DRGs": "DRG#7: Human Agency & Identity"
  },
  {
    "Criterion/Metric Name": "Interoperability & Portability",
    "DRG Short Code": "4",
    "Question": "To what extent does the organisation provide data in standard, machine‑readable formats and make it easy for users to transfer their data or switch providers?",
    "Rationale": "Practical portability reduces lock‑in, empowers users, and fosters competition and innovation.",
    "Scoring Logic": "0=None; 1=Limited; 2=Standardised; 3=Portable",
    "Legend": "None – no machine-readable data outputs; Limited – data only available in hard-to-use or proprietary formats (e.g., PDF); Standardised – data available in common, machine-readable formats (e.g., CSV, XML, JSON) aligned with open standards; Portable – data provided in a way that enables easy transfer or switching to another provider/service (e.g., standardised exports, direct import functions, or interoperable APIs)",
    "Primary DRG": "DRG#4: Data Fairness",
    "Other Applicable DRGs": "DRG#6: Transparency"
  },
  {
    "Criterion/Metric Name": "Participation in Data Altruism",
    "DRG Short Code": "4",
    "Question": "Does the organisation participate in recognised data‑altruism initiatives or voluntarily provide data for public‑good research projects?",
    "Rationale": "Responsible sharing for public benefit creates societal value and builds transparency and trust.",
    "Scoring Logic": "0=None; 3=Exists",
    "Legend": "None – organisation does not provide data voluntarily for public-good purposes; Exists – organisation participates in recognised data altruism initiatives, is formally registered (e.g., under EU Data Governance Act), or provides data voluntarily to research efforts or other public-good projects",
    "Primary DRG": "DRG#4: Data Fairness",
    "Other Applicable DRGs": "–"
  },
  {
    "Criterion/Metric Name": "Algorithmic Impact Assessments Conducted",
    "DRG Short Code": "5",
    "Question": "To what extent does the organisation assess the ethical and societal impacts of algorithms and automated decision‑making before and during deployment?",
    "Rationale": "Impact assessments help identify and mitigate risks such as bias, unfair outcomes, and unintended harms.",
    "Scoring Logic": "0=None; 1=Ad hoc; 2=Planned; 3=Applied; 4=Systematic; 5=Embedded",
    "Legend": "None – no ethical or impact assessment of algorithms; Ad hoc – informal checks or discussions only; Planned – framework for assessments exists but not consistently applied; Applied – assessments conducted for some algorithms affecting users; Systematic – assessments required and carried out for all significant algorithmic systems; Embedded – assessments fully integrated into governance with transparency and external review",
    "Primary DRG": "DRG#5: Trustworthy Algorithms",
    "Other Applicable DRGs": "DRG#6: Transparency"
  },
  {
    "Criterion/Metric Name": "AI Ethics Board & Oversight",
    "DRG Short Code": "5",
    "Question": "What form of ethical oversight exists for algorithmic projects (e.g., guidelines for teams, assigned oversight, or a reviewing committee)?",
    "Rationale": "Structured oversight aligns algorithmic development with organisational values and public expectations, improving accountability.",
    "Scoring Logic": "0=None; 1=Ad hoc; 2=Guidelines; 3=Oversight assigned; 4=Committee; 5=Integrated",
    "Legend": "None – no ethical oversight of algorithms; Ad hoc – informal awareness or one-off discussions; Guidelines – AI ethics guidelines or principles exist for staff/project teams; Oversight assigned – responsibility for AI ethics assigned to existing governance functions (e.g., compliance, risk, legal); Committee – dedicated AI ethics committee or working group established, reviewing algorithmic projects; Integrated – oversight fully embedded in governance with clear authority, transparency, and regular reporting to leadership",
    "Primary DRG": "DRG#5: Trustworthy Algorithms",
    "Other Applicable DRGs": "DRG#6: Transparency, DRG#3: Privacy"
  },
  {
    "Criterion/Metric Name": "Public Digital Ethics Principles Published",
    "DRG Short Code": "6",
    "Question": "Has the organisation published ethical AI or digital responsibility principles, and does it report on their implementation?",
    "Rationale": "Publishing principles and reporting on progress provides transparency and enables external accountability.",
    "Scoring Logic": "0=None; 1=Published; 2=Reported",
    "Legend": "None – no published ethical AI or digital responsibility principles; Published – principles are published but no regular reporting; Reported – principles are published and the organisation regularly reports on their implementation",
    "Primary DRG": "DRG#6: Transparency",
    "Other Applicable DRGs": "DRG#5: Trustworthy Algorithms"
  },
  {
    "Criterion/Metric Name": "Clear Privacy Policy & Data Use Disclosure",
    "DRG Short Code": "6",
    "Question": "How clear, findable, and well‑structured are the organisation´s privacy policies and data‑use notices?",
    "Rationale": "Plain, well‑structured policies reduce information asymmetry and help users understand how their data is used.",
    "Scoring Logic": "0=None; 1=Minimal; 2=Complete; 3=Clear & user-friendly",
    "Legend": "None – no accessible privacy policy; Minimal – policy exists but vague, incomplete, or hard to find; Complete – policy covers required legal elements (e.g., what data, purposes, sharing) and is findable, but written in complex or legalistic style; Accessible & user-friendly – policy is complete, easy to find, well-structured (e.g., FAQs, layered notices), and written in plain language with examples",
    "Primary DRG": "DRG#6: Transparency",
    "Other Applicable DRGs": "DRG#3: Privacy"
  },
  {
    "Criterion/Metric Name": "Open Communication Channels",
    "DRG Short Code": "6",
    "Question": "How accessible and responsive are the organisation´s channels for user questions about digital products and services?",
    "Rationale": "Easy‑to‑find, supportive channels improve user trust and reduce friction when issues arise.",
    "Scoring Logic": "0=None; 1=Basic; 2=Available; 3=Accessible & supportive",
    "Legend": "None – no channel for user questions on digital products/services; Basic – channel exists but limited (e.g., generic email, hard to find); Available – clear channel provided and functional (e.g., helpdesk, chat, hotline), but limited support; Accessible & supportive – multiple accessible channels (e.g., phone, chat, email) easy to find and responsive, designed to support all users",
    "Primary DRG": "DRG#6: Transparency",
    "Other Applicable DRGs": ""
  },
  {
    "Criterion/Metric Name": "Stakeholder Engagement",
    "DRG Short Code": "7",
    "Question": "How regularly and systematically are stakeholders (e.g., users, employees, communities, regulators) engaged in the design and evaluation of digital initiatives?",
    "Rationale": "Meaningful engagement surfaces risks early, aligns services with real needs, and improves legitimacy.",
    "Scoring Logic": "0=None; 1=Ad hoc; 2=Consulted; 3=Structured; 4=Integrated",
    "Legend": "None – no stakeholder involvement; Ad hoc – occasional, informal input (e.g., survey during rollout); Consulted – stakeholders asked for feedback in some projects (e.g., focus groups, employee input); Structured – regular, documented engagement with stakeholders (e.g., user panels, regulator workshops) influencing outcomes; Integrated – stakeholder engagement embedded in governance/strategy with ongoing dialogue and accountability (e.g., advisory panels, community reps)",
    "Primary DRG": "DRG#7: Human Agency & Identity",
    "Other Applicable DRGs": "DRG#6: Transparency"
  },
  {
    "Criterion/Metric Name": "Sustainable Development Goals",
    "DRG Short Code": "7",
    "Question": "To what extent are digital initiatives aligned with the UN Sustainable Development Goals and reported on?",
    "Rationale": "Linking digital work to SDGs connects business outcomes to societal value and enables clearer impact reporting.",
    "Scoring Logic": "0=None; 1=Referenced; 2=Aligned; 3=Integrated; 4=Reported",
    "Legend": "None – no reference to SDGs; Referenced – SDGs mentioned in strategy or policies, but not linked to activities; Aligned – specific digital initiatives linked to selected SDGs; Integrated – SDGs embedded into organisational strategy and decision-making; Reported – regular public reporting on progress against SDG targets with evidence",
    "Primary DRG": "DRG#7: Human Agency & Identity",
    "Other Applicable DRGs": ""
  },
  {
    "Criterion/Metric Name": "Board-Level Digital-Risk Governance",
    "DRG Short Code": "7",
    "Question": "Are digital and cybersecurity risks explicitly addressed in board‑level governance (e.g., documented roles, regular reporting)?",
    "Rationale": "Board attention ensures adequate investment and accountability for digital and cyber risks.",
    "Scoring Logic": "0=None; 1=Ad hoc; 2=Documented; 3=Integrated",
    "Legend": "None – no evidence that digital/cyber risks are considered at board level; Ad hoc – risks occasionally discussed but not formalised in governance; Documented – digital/cyber risks explicitly included in board governance documents (e.g., risk registers, charters); Integrated – board regularly addresses digital/cyber risks with structured reporting and accountability",
    "Primary DRG": "DRG#7: Human Agency & Identity",
    "Other Applicable DRGs": ""
  }
]
